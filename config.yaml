paths:
  raw_pdfs: data/raw_pdfs/
  issues_json: data/json/
  chunks: data/chunks/
  embeddings: data/embeddings/
  index: data/index/

chunking:
  page_break_token: "<PAGE_BREAK>" # ← must match token used in Phase 1 JSONs
  size_words: 900 # target ~900 words per chunk
  overlap_words: 120 # overlap between consecutive chunks
  min_words: 50 # minimum chunk size (only for merging tails)

embeddings:
  model_name: "all-MiniLM-L6-v2"
  normalize: true

index:
  backend: "faiss"
  dim: 384

paths:
  chunks: "data/chunks"

summarization:
  model_name: "t5-small" # or "facebook/bart-base"
  max_input_tokens: 512 # truncate input tokens
  max_new_tokens: 120 # ~2–4 sentences
  num_beams: 4 # quality vs speed
  batch_size: 4 # keep small on CPU
  output_dir: "data/summaries"
  device: "auto" # "auto" | "cpu" | "cuda"


metadata:
  issue_id_regex: "(\\d{4})[\\-_](\\d{2})"
  default_lang: "en"
  parser_version: "1.0.0"
  summarizer_defaults:
    model: "t5-small"
    num_beams: 4
  paths:
    pdf_dir: "data/raw_pdfs"
    chunks_dir: "data/chunks"
    summaries_dir: "data/summaries"
    enriched_dir: "data/enriched"
